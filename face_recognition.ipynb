{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/davidalba/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.10.0.84)\n",
      "Requirement already satisfied: numpy in /home/davidalba/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/davidalba/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.8.0)\n",
      "Requirement already satisfied: tensorflow in /home/davidalba/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (1.65.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorflow->-r requirements.txt (line 4)) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 4)) (0.41.2)\n",
      "Requirement already satisfied: rich in /home/davidalba/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 4)) (13.3.5)\n",
      "Requirement already satisfied: namex in /home/davidalba/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 4)) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/davidalba/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 4)) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 4)) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/davidalba/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 4)) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Layer, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Memory growth must be set before GPUs have been initialized\")\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[01;34mapplication_data\u001b[0m\n",
      "│   ├── \u001b[01;34minput_image\u001b[0m\n",
      "│   └── \u001b[01;34mverification_images\u001b[0m\n",
      "├── \u001b[01;34mcheckpoints\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   ├── \u001b[01;34mmatched\u001b[0m\n",
      "│   ├── \u001b[01;34msamples\u001b[0m\n",
      "│   └── \u001b[01;34munmatched\u001b[0m\n",
      "├── \u001b[01;34mdataset\u001b[0m\n",
      "│   └── \u001b[01;31mlfw.tgz\u001b[0m\n",
      "├── \u001b[00mface_recognition.ipynb\u001b[0m\n",
      "├── \u001b[00mREADME.md\u001b[0m\n",
      "├── \u001b[00mrequirements.txt\u001b[0m\n",
      "└── \u001b[01;34msave_model\u001b[0m\n",
      "\n",
      "11 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "project_path = os.path.curdir\n",
    "\n",
    "data_path = os.path.join(project_path, 'data')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Directorios\n",
    "matched_path = os.path.join(data_path, 'matched')\n",
    "unmatched_path = os.path.join(data_path,'unmatched')\n",
    "samples_path = os.path.join(data_path, 'samples')\n",
    "dataset_path = os.path.join(project_path, 'dataset')\n",
    "app_data_path = os.path.join(project_path,'application_data')\n",
    "verific_path = os.path.join(app_data_path,'verification_images')\n",
    "input_image_path = os.path.join(app_data_path, 'input_image')\n",
    "save_model_path = os.path.join(project_path, 'save_model')\n",
    "checkpoint_path = os.path.join(project_path,'checkpoints')\n",
    "\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "os.makedirs(matched_path, exist_ok=True)\n",
    "os.makedirs(unmatched_path, exist_ok=True)\n",
    "os.makedirs(samples_path, exist_ok=True)\n",
    "os.makedirs(app_data_path,exist_ok=True)\n",
    "os.makedirs(verific_path,exist_ok=True)\n",
    "os.makedirs(input_image_path,exist_ok=True)\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "os.makedirs(save_model_path, exist_ok=True)\n",
    "\n",
    "!tree -L 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file lfw.tgz is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(dataset_path, 'lfw.tgz')):\n",
    "    !wget http://vis-www.cs.umass.edu/lfw/lfw.tgz -P {dataset_path}\n",
    "else:\n",
    "    print('The file lfw.tgz is already downloaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking and Extracting Unmatched Directory Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"unmatched\" directory already contains 13233 files:\n",
      "Sanjay_Gupta_0001.jpg\n",
      "Erik_Morales_0002.jpg\n",
      "Nadia_Petrova_0002.jpg\n",
      "Gerhard_Schroeder_0028.jpg\n",
      "George_W_Bush_0101.jpg\n",
      "Zhu_Rongji_0009.jpg\n",
      "Gary_Condit_0001.jpg\n",
      "Yusuf_Misbac_0001.jpg\n",
      "Junichiro_Koizumi_0031.jpg\n",
      "Alvaro_Uribe_0022.jpg\n"
     ]
    }
   ],
   "source": [
    "if len(os.listdir(unmatched_path)) > 0:\n",
    "    print(f'The \"unmatched\" directory already contains {len(os.listdir(unmatched_path))} files:')\n",
    "    print('\\n'.join(os.listdir(unmatched_path)[:10]))\n",
    "else:\n",
    "    !tar -xzf {os.path.join(dataset_path, 'lfw.tgz')} -C {unmatched_path} --strip-components 1\n",
    "    print('File extracted in the \"unmatched\" directory.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Files from Subdirectories to the Unmatched Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13233 images in the 'unmatched' directory and no subdirectories found.\n"
     ]
    }
   ],
   "source": [
    "if any(os.path.isdir(os.path.join(unmatched_path, d)) for d in os.listdir(unmatched_path)):\n",
    "    print(\"Moving files from subdirectories to the 'unmatched' directory...\")\n",
    "    for subdir in os.listdir(unmatched_path):\n",
    "        subdir_path = os.path.join(unmatched_path, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                src = os.path.join(subdir_path, filename)\n",
    "                dst = os.path.join(unmatched_path, filename)\n",
    "                os.replace(src, dst)\n",
    "            os.rmdir(subdir_path)\n",
    "    print(\"Files moved and folders deleted.\")\n",
    "else:\n",
    "    num_images = len(os.listdir(unmatched_path))\n",
    "    print(f\"There are {num_images} images in the 'unmatched' directory and no subdirectories found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_images(samples_path, matched_path):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count_samples = 0\n",
    "    count_matched = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = frame[120:120+250, 200:200+250, :]\n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('s'):\n",
    "            imgname = os.path.join(samples_path, f'{uuid.uuid1()}.jpg')\n",
    "            cv2.imwrite(imgname, frame)\n",
    "            count_samples += 1\n",
    "            print(f'Samples image saved: {imgname}')\n",
    "        elif key == ord('a'):\n",
    "            imgname = os.path.join(matched_path, f'{uuid.uuid1()}.jpg')\n",
    "            cv2.imwrite(imgname, frame)\n",
    "            count_matched += 1\n",
    "            print(f'Matched image saved: {imgname}')\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return count_samples, count_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n",
      "QObject::moveToThread: Current thread (0x7e1a2b0) is not the object's thread (0x8796620).\n",
      "Cannot move to target thread (0x7e1a2b0)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_images(samples_path,matched_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_image_count(desired_count, *directories):\n",
    "    for directory in directories:\n",
    "        current_count = len(os.listdir(directory))\n",
    "        if current_count < desired_count:\n",
    "            raise ValueError(f'A minimum of {desired_count} images are required in {directory}, but only {current_count} were found.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Modify the 'num_images' variable to adjust the number of images to be processed.\n",
    "num_images = 300 \n",
    "\n",
    "validate_image_count (num_images,matched_path,samples_path,unmatched_path) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de datos para entrenamiento\n",
    "matched_dataset = tf.data.Dataset.list_files(matched_path + '/*.jpg').take(num_images)\n",
    "samples_dataset = tf.data.Dataset.list_files(samples_path + '/*.jpg').take(num_images)\n",
    "unmatched_dataset = tf.data.Dataset.list_files(unmatched_path + '/*.jpg').take(num_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Image Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "  \n",
    "    byte_img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(byte_img, channels=3)  # Asegura que la imagen tenga 3 canales (RGB)\n",
    "    img = tf.image.resize(img, (105, 105))\n",
    "    img = img / 255.0  # Normaliza los valores de los píxeles a [0, 1]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creation of the Training Dataset\n",
    "\n",
    "positives = tf.data.Dataset.zip((\n",
    "    samples_dataset,\n",
    "    matched_dataset,\n",
    "    tf.data.Dataset.from_tensor_slices(tf.ones(len(samples_dataset)))  # Label '1' for positive pairs\n",
    "))\n",
    "\n",
    "negatives = tf.data.Dataset.zip((\n",
    "    samples_dataset,\n",
    "    unmatched_dataset,\n",
    "    tf.data.Dataset.from_tensor_slices(tf.zeros(len(samples_dataset)))  # Label '0' for negative pairs\n",
    "))\n",
    "\n",
    "# Combine positive and negative datasets\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pair preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pair(sample_image, validation_image, label):\n",
    "    return preprocess_image(sample_image), preprocess_image(validation_image), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the preprocessing function to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess_pair) # Aplica la función de preprocesamiento al dataset \n",
    "data = data.cache() #Almacena en caché el dataset para mejorar la eficiencia.\n",
    "data = data.shuffle(buffer_size=1024) #Baraja el dataset con un buffer de 1024 elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training and testing sets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toma el 70% del conjunto de datos para entrenamiento\n",
    "train_data = data.take(round(len(data) * 0.7))\n",
    "\n",
    "# Optimización de Recursos\n",
    "\n",
    "# Agrupa los elementos en lotes de 16\n",
    "train_data = train_data.batch(16)\n",
    "\n",
    "# Superpone el procesamiento y entrenamiento con prefetch de 8 lotes\n",
    "train_data = train_data.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_embedding(): \n",
    "    inp = Input(shape=(105, 105, 3), name='input_image')\n",
    "    \n",
    "    c1 = Conv2D(64, (10, 10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(pool_size=(2, 2), padding='same')(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, (7, 7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(pool_size=(2, 2), padding='same')(c2)\n",
    "    \n",
    "    c3 = Conv2D(128, (4, 4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(pool_size=(2, 2), padding='same')(c3)\n",
    "    \n",
    "    c4 = Conv2D(256, (4, 4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=d1, name='embedding')\n",
    "\n",
    "# Se define una red neuronal convolucional (CNN) para extraer embeddings (representaciones de características) de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia L1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define una capa personalizada para calcular la distancia L1 (la suma de las diferencias absolutas) entre dos vectores.\n",
    "\n",
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        return tf.abs(inputs[0] - inputs[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    input_sample_image = Input(shape=(105, 105, 3), name='sample_image')\n",
    "    input_validation_image = Input(shape=(105, 105, 3), name='validation_image')\n",
    "    \n",
    "    embedding_model = make_embedding()\n",
    "    \n",
    "    encoded_s = embedding_model(input_sample_image)\n",
    "    encoded_v = embedding_model(input_validation_image)\n",
    "    \n",
    "    distance = L1Dist(name='distance')([encoded_s, encoded_v])\n",
    "    \n",
    "    classifier = Dense(1, activation='sigmoid')(distance)\n",
    "    \n",
    "    model = Model(inputs=[input_sample_image, input_validation_image], outputs=classifier, name='siamese_network')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 12:05:16.525605: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n",
      "2024-08-01 12:05:17.528085: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"siamese_network\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"siamese_network\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sample_image        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_image    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> │ sample_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ validation_image… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L1Dist</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> │ l1_dist_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sample_image        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m, \u001b[38;5;34m105\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_image    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m, \u001b[38;5;34m105\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │ \u001b[38;5;34m38,960,448\u001b[0m │ sample_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ validation_image… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_1 (\u001b[38;5;33mL1Dist\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m4,097\u001b[0m │ l1_dist_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Note :***\n",
    "> ***I could have chosen a simpler approach using Keras' compile function, but I decided to implement the training process manually.\n",
    "This allowed me to understand in detail each step involved in training the model. Although I haven't tested the following code,\n",
    "it should work fine. Here's the streamlined approach:***\n",
    "\n",
    "```python\n",
    "\n",
    "siamese_model = make_siamese_model()\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Precision(), Recall()])\n",
    "\n",
    "history = siamese_model.fit(train_data, \n",
    "                            validation_data=test_data,\n",
    "                            epochs=5,\n",
    "                            batch_size=16)\n",
    "\n",
    "plt.plot(history.history['precision'], label='Precision')\n",
    "plt.plot(history.history['recall'], label='Recall')\n",
    "plt.title('Precision and Recall of Siamese Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define binary cross-entropy loss function\n",
    "binary_cross_entropy_loss = tf.losses.BinaryCrossentropy()\n",
    "\n",
    "# Initialize Adam optimizer with a learning rate of 0.0001\n",
    "adam_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_path, 'ckpt')\n",
    "model_checkpoint = tf.train.Checkpoint(opt=adam_optimizer, siamese_model=siamese_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def training_step(batch):\n",
    "    # Record all operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Extract images and labels from the batch\n",
    "        input_images = batch[:2]  # Anchor and positive/negative images\n",
    "        true_labels = batch[2]    # Labels\n",
    "        \n",
    "        # Perform a forward pass through the Siamese model\n",
    "        predicted_labels = siamese_model(input_images, training=True)\n",
    "        \n",
    "        # Compute the binary cross-entropy loss\n",
    "        loss_value = binary_cross_entropy_loss(true_labels, predicted_labels)\n",
    "        print(loss_value)  # Print the loss for monitoring\n",
    "        \n",
    "    # Compute gradients of the loss with respect to model variables\n",
    "    gradients = tape.gradient(loss_value, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Apply gradients to update model weights\n",
    "    adam_optimizer.apply_gradients(zip(gradients, siamese_model.trainable_variables))\n",
    "    \n",
    "    # Return the computed loss for further analysis\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data, num_epochs):\n",
    "    # Loop through each epoch\n",
    "    for current_epoch in range(1, num_epochs + 1):\n",
    "        print('\\n Epoch {}/{}'.format(current_epoch, num_epochs))\n",
    "        progress_bar = tf.keras.utils.Progbar(len(training_data))\n",
    "        \n",
    "        # Create metric objects for evaluation\n",
    "        recall_metric = Recall()\n",
    "        precision_metric = Precision()\n",
    "        \n",
    "        # Loop through each batch in the training data\n",
    "        for batch_index, current_batch in enumerate(training_data):\n",
    "            # Execute the training step for the current batch\n",
    "            loss_value = training_step(current_batch)\n",
    "            \n",
    "            # Make predictions using the Siamese model\n",
    "            predicted_labels = siamese_model.predict(current_batch[:2])\n",
    "            \n",
    "            # Update recall and precision metrics\n",
    "            recall_metric.update_state(current_batch[2], predicted_labels)\n",
    "            precision_metric.update_state(current_batch[2], predicted_labels) \n",
    "            \n",
    "            # Update the progress bar\n",
    "            progress_bar.update(batch_index + 1)\n",
    "        \n",
    "        # Print the loss, recall, and precision for the current epoch\n",
    "        print(loss_value.numpy(), recall_metric.result().numpy(), precision_metric.result().numpy())\n",
    "        \n",
    "        # Save checkpoints every 10 epochs\n",
    "        if current_epoch % 10 == 0: \n",
    "            model_checkpoint.save(file_prefix=checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True \n",
    "if(train):\n",
    "    train_model(train_data,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Recall: 0.13684210181236267, Precision: 0.21311475336551666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 12:06:29.293565: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Inicializar métricas de Recuperación y Precisión para la evaluación sobre los datos de prueba\n",
    "recall_metric = Recall()\n",
    "precision_metric = Precision()\n",
    "\n",
    "for sample_image, validate_image, true_label in test_data.as_numpy_iterator():\n",
    "    # Obtener las predicciones del modelo siamesa\n",
    "    predict_label = siamese_model.predict([sample_image,validate_image])\n",
    "    # Actualizar la métrica de Recuperación con las etiquetas verdaderas y las predicciones\n",
    "    recall_metric.update_state(true_label, predict_label)\n",
    "    # Actualizar la métrica de Precisión con las etiquetas verdaderas y las predicciones\n",
    "    precision_metric.update_state(true_label, predict_label)\n",
    "\n",
    "\n",
    "# Print final recall and precision results\n",
    "print(f'Recall: {recall_metric.result().numpy()}, Precision: {precision_metric.result().numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_siamese_model(save_model_path, date_str=None):\n",
    "    custom_objects = {\n",
    "        'L1Dist': L1Dist,\n",
    "        'BinaryCrossentropy': tf.losses.BinaryCrossentropy\n",
    "    }\n",
    "\n",
    "    if date_str:\n",
    "        # Si se proporciona una fecha, intenta cargar el modelo correspondiente\n",
    "        model_filename = f\"siamese_model_{date_str}.h5\"\n",
    "        model_filepath = os.path.join(save_model_path, model_filename)\n",
    "        if os.path.exists(model_filepath):\n",
    "            print(f\"Cargando el modelo desde: {model_filepath}\")\n",
    "            return tf.keras.models.load_model(model_filepath, custom_objects=custom_objects)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No se encontró el modelo para la fecha proporcionada: {date_str}\")\n",
    "    else:\n",
    "        # Si no se proporciona una fecha, carga el modelo más reciente\n",
    "        model_files = [f for f in os.listdir(save_model_path) if f.startswith(\"siamese_model_\") and f.endswith(\".h5\")]\n",
    "        if not model_files:\n",
    "            raise FileNotFoundError(\"No se encontraron modelos en el directorio especificado.\")\n",
    "        \n",
    "        # Ordenar los archivos por fecha y hora en el nombre del archivo\n",
    "        model_files.sort(key=lambda x: datetime.datetime.strptime(x.split(\"_\", 2)[2].split(\".\")[0], \"%Y_%m_%d_%H_%M\"), reverse=True)\n",
    "        latest_model_filename = model_files[0]\n",
    "        latest_model_filepath = os.path.join(save_model_path, latest_model_filename)\n",
    "        print(f\"Cargando el modelo más reciente desde: {latest_model_filepath}\")\n",
    "        return tf.keras.models.load_model(latest_model_filepath, custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "model_filename = f\"siamese_model_{current_datetime}.h5\"\n",
    "\n",
    "# Guardar el modelo en el subdirectorio\n",
    "siamese_model.save(os.path.join(save_model_path,model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el modelo más reciente desde: ./save_model/siamese_model_2024_08_01_12_06.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Para cargar un modelo específico por fecha\n",
    "# model = load_siamese_model(save_model_path, \"2024_08_01_12_00\")\n",
    "\n",
    "# Para cargar el modelo más reciente\n",
    "try:\n",
    "    siamese_model = load_siamese_model(save_model_path)\n",
    "except Exception as e:\n",
    "    print(f'Error loading model: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"siamese_network\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"siamese_network\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sample_image        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_image    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> │ sample_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ validation_image… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L1Dist</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> │ l1_dist_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sample_image        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m, \u001b[38;5;34m105\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_image    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m, \u001b[38;5;34m105\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │ \u001b[38;5;34m38,960,448\u001b[0m │ sample_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ validation_image… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_2 (\u001b[38;5;33mL1Dist\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m4,097\u001b[0m │ l1_dist_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View model summary\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    # Build results array\n",
    "    results = []\n",
    "    input_img = preprocess_image(os.path.join(input_image_path,'input_image.jpg'))\n",
    "    \n",
    "    for image in verific_path:\n",
    "        validation_img = preprocess_image(os.path.join(verific_path,image))\n",
    "        \n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "    \n",
    "    # Detection Threshold: Metric above which a prediciton is considered positive \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    \n",
    "    # Verification Threshold: Proportion of positive predictions / total positive samples \n",
    "    verification = detection / len(os.listdir(os.path.join(verific_path))) \n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1084.194] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@1084.420] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    cv2.imshow('Verification', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "  \n",
    "        cv2.imwrite(os.path.join(input_image_path,'input_image.jpg'), frame)\n",
    "        # Run verification\n",
    "        results, verified = verify(siamese_model, 0.5, 0.5)\n",
    "        print(verified)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mostrar los resultados\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNúmero de resultados mayores a 0.9:\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msqueeze(results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.9\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResultados:\u001b[39m\u001b[38;5;124m'\u001b[39m, results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mostrar los resultados\n",
    "print('Número de resultados mayores a 0.9:', np.sum(np.squeeze(results) > 0.9))\n",
    "print('Resultados:', results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
